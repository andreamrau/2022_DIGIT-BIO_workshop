---
title: "Do my clusters make sense? Some statistical and biological clues to help..."
subtitle: "DIGIT-BIO tutorial @ Ecully"
date: 8 December 2022
author:
- name: Andrea Rau
  affiliation: andrea.rau@inrae.fr, https://andrea-rau.com
output:
  BiocStyle::html_document:
    toc: yes
abstract: |
  [Unsupervised classification (clustering)](https://digitbio-ia.github.io/sequences/concepts/s2_clustering) is used in many fields. But once a clustering result has been obtained, how can we evaluate its pertinence? In this work, we will work with several statistical and biological indices to reinforce our confidence (or not...) in a clustering result. We will use as an example the identification of co-expressed genes from transcriptomic data with finite mixture models. 

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# knitr::purl("2022_DIGIT-BIO-atelier.Rmd")
```


![](digitbio_logo.png)

# Getting started

We will first begin by installing the necessary packages for this tutorial:
```{r, eval = FALSE}
install.packages("BiocManager")
BiocManager::install(c("mclust", "clValid", "fpc", "ggplot2", "coseq",
                        "clusterProfiler", "org.Mm.eg.db"))
```

In some cases, installation of the `r Biocpkg("clusterProfiler")` package may cause
errors due to a dependence on the `r Biocpkg("ggtree")` package (see [here](https://github.com/YuLab-SMU/ggtree/issues/544)). In this case, you can try
using the following code to install the development version of `r Biocpkg("ggtree")`
before installing the remaining packages as described above.

```{r, eval=FALSE}
install.packages("remotes")
remotes::install_github('YuLab-SMU/ggtree')
```

Installation of all packages should take approximately ~15 min. Some participants
have experienced difficulties installing the `r Biocpkg("clusterProfiler")` and
`r Biocpkg("org.Mm.eg.db")` packages; note that these two packages are only
used in the final section on external validation, and the remainder of the 
tutorial can be run without them.

# Load packages and pre-formatted results

Next, we load all packages for the tutorial.

```{r, warning=FALSE, message=FALSE}
library(clValid)          ## Package with several validation criteria
library(fpc)              ## Package with several validation criteria
library(mclust)           ## Package to fit Gaussian mixture models
library(coseq)            ## Co-expression analyses
library(ggplot2)          ## Plotting 

library(clusterProfiler)  ## GO enrichment analysis
library(org.Mm.eg.db)     ## Mouse annotation
```

In this tutorial, we will make use of data from an RNA-seq experiment to study 
lineage of luminal cells in mouse mammary gland and changes in expression upon 
pregnancy and lactation ([Fu et al., 2015](https://pubmed.ncbi.nlm.nih.gov/25730472/)). The study included 2 cell types 
{basal stem-cell enriched cells, committed luminal cells} × 3 statuses {virgin, 
pregnant, lactating} × 2 biological replicates. Illumina HiSeq was used to 
produce 30 million 100bp SE reads. Pre-processing steps included alignment of 
reads to the mm10 genome with *Subread* and quantification of Entrez genes 
(RefSeq) using *featureCounts*. Further details about the study and these
pre-processing steps can be found 
[here](https://bioconductor.org/packages/release/workflows/vignettes/RnaSeqGeneEdgeRQL/inst/doc/edgeRQL.html)).

Prior to this tutorial, raw counts from the study were downloaded and subjected
to an initial analysis. Specifically, (1) genes with weak expression or 
ambiguous/missing IDs were filtered from the analysis, and `r Biocpkg("DESeq2")`
was used to perform library size normalization; (2) a differential analysis to
identify genes with significantly differentially expression in at least one 
status group (results are saved in an RDS object called `Fu-GSE60450_dds.rds`); 
and (3) two co-expression analyses were performed on 
arcsine-transformed RNA-seq profiles using `r Biocpkg("coseq")`:

1. **Gaussian mixture models** (GMM), using 20 independent runs over a range of 
cluster values from $K$=2, ..., 20, with the best performer selected using the 
ICL criterion. Results are saved in an RDS object called `coexp_gmm.rds`.
2. **K-means** algorithm over a range of cluster values from $K$=2, ..., 20, 
with the best performer selected using the slope heuristics criterion. 
Results are saved in an RDS object called `coexp_km.rds`.

We will examine a variety of cluster validation metrics on these two clustering
results in the following tutorial. Note that code to regenerate these results 
can be found in the Appendix. For the purposes of this tutorial, all necessary 
pre-processed data files can be found on the associated 
[GitHub repo](https://github.com/andreamrau/2022_DIGIT-BIO_workshop).

To download the tutorial materials, you can navigate to the 
[GitHub repo](https://github.com/andreamrau/2022_DIGIT-BIO_workshop) and click
on the green `Code` button to download a zipped file, as shown in the
screenshot below.

![](github_screenshot.png)

After unzipping the file, the data files can be found in the `2022_DIGIT-BIO_workshop-main/data/` folder, and R/Rmarkdown scripts in the
`2022_DIGIT-BIO_workshop-main/code/` folder. For interactively rerunning
the scripts in this tutorial, you can open the `2022_DIGIT-BIO-atelier.R`
file in R or RStudio. For the remainder, make sure that your current working
directory is in your `2022_DIGIT-BIO_workshop-main/code/` folder by using 
the `getwd()` command to see your current working directory, and as needed
`setwd(...)` to change it.

The files we will use in this tutorial are in `.rds` format, which is used
to write a single `R` object to a file enabling it to be easily restored. We
have used this format here since output from `r Biocpkg("coseq")` is not in 
simple tabular format, as it includes meta-data such as posterior probabilities
of cluster membership, model selection criteria values, input data, etc.

We then load these results below, and set the seed for the random number 
generator to ensure reproducible results:

```{r}
dds <- readRDS("../data/Fu-GSE60450_dds.rds")
coexp_gmm <- readRDS("../data/coexp_gmm.rds")
coexp_km <- readRDS("../data/coexp_km.rds")
set.seed(12345)
```

The data input into each of the clustering algorithms is a square table
of transformed normalized profile values,
with $n$=2317 genes in rows and $p$=12 samples in columns:

```{r}
tcounts(coexp_gmm)
```

We have clustered rows of this data table to identify genes with similar expression patterns across the 12 experimental samples.
Note that the clustering algorithms here do not make use of the sample labels 
(e.g., cell type, status). However, we will visualize the identified clusters
with respect to these labels in the graphics in the following section.

# Examine `r Biocpkg("coseq")` clustering results

We first briefly examine the results for the two
`r Biocpkg("coseq")` clusterings. We start with the GMM results,
and examine boxplots of the co-expression clusters. In the boxplots below, each
facet represents an identified cluster, and boxplots for each of the 12
samples represent the respective normalized profile values for genes assigned
to that cluster.

```{r}
coexp_gmm
plot(coexp_gmm, conds = dds$Status, graph = "boxplots")
```

To better visualize the cluster-specific patterns of expression with respect
to status, we can represent these same clusters by summing normalized
profile values by status group for each gene.

```{r}
plot(coexp_gmm, conds = dds$Status,
     collapse_reps = "average", graph = "boxplots")
```

Finally, we can consider the conditional probabilities of cluster membership
for each cluster.


```{r}
plot(coexp_gmm, graphs = "probapost_boxplots")
```

Note that clusters that
have very sharp, marked profiles (e.g. Cluster 10) tend to include genes
with higher conditional probabilities. Genes assigned to clusters with less
marked profiles (e.g., Cluster 1 or 3) likely have a more ambiguous 
clustering assignment, which is reflected by the larger range of values for
the respective conditional probabilities.


We similarly examine results from the K-means algorithm. Note that clustering
labels are arbitrary, so Cluster 1 from the GMM does not have any link to
Cluster 1 from K-means. By exploiting the relationship between the K-means
algorithm and a special case of the GMM (notably, spherical GMMs with
estimation via the CEM algorithm), we can similarly calculate conditional
probabilities of cluster assignment analagous to those seen above.

```{r}
coexp_km
plot(coexp_km, conds = dds$Status,
     collapse_reps = "average", graph = "boxplots")
plot(coexp_km, graphs = "probapost_boxplots")
```

# Internal validation

Internal cluster validation seeks to evaluate the goodness of clustering 
structure using data alone. In other words, we aim to evaluate the 
extent to which genes with a given cluster are similar, as well as the extent to 
which genes in different clusters are distinct. Measures of internal validation
are typically defined using measures of (1) *compactness*, 
(2) *connectivity*, and/or (3) *separation*.

In this section, we will examine two criteria for internal cluster validation:
the Silhouette width, and the Dunn index. For each of these, note that we make
use of the transformed normalized counts produced internally for clustering
by `r Biocpkg("coseq")`, accessible using `tcounts(coexp_gmm)`, rather than the raw counts.

## Silhouette width 

The silhouette statistic is a measure of how closely data within a cluster is
matched (compactness) and how loosely it is matched to neighboring
clusters (separation). It is defined as follows:

\[ a(i) = \frac{1}{\vert C_I \vert - 1}\sum_{j\in C_I, i \ne j} d(i,j) \text{ and } b(i) = \min_{J\ne I} \frac{1}{\vert C_J \vert}\sum_{j\in C_J} d(i,j)  \textsf{, for } i \in C_I\]

\[ s(i) = \frac{b(i)-a(i)}{\max \lbrace a(i), b(i) \rbrace} \]

The silhouette width can take values from -1 to 1. **Observations (genes) with a large silhouette width are typically considered to be well clustered**, 
while values close to 0 may indicate that an 
observation lies between two clusters. Observations with a negative $s_i$ 
may be assigned to an incorrect cluster. 

The results for the GMM clustering are shown below. In the graphic, genes
are plotted on the x-axis, and $s_i$ values on the y-axis, with different
colors representing each cluster. Which clusters appear to be the best formed? 
Which are the fuzziest?


```{r, cache=TRUE}
sil_gmm <- cluster::silhouette(clusters(coexp_gmm), dist(tcounts(coexp_gmm)))
summary(sil_gmm)
sil_df_gmm <- data.frame(as(sil_gmm, "matrix"))
sil_df_gmm$Cluster <- factor(sil_df_gmm$cluster)
sil_df_gmm <- sil_df_gmm[order(sil_df_gmm$cluster, sil_df_gmm$sil_width),]
ggplot(sil_df_gmm) +
  geom_col(aes(x=1:nrow(sil_df_gmm), y=sil_width, fill = Cluster)) + 
  ylab("Silhouette width") + 
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```

We now examine the same results for the K-means results. What do you notice?

One thing to keep in mind is that the
silhouette statistic is defined above using a distance $d(i,j)$, typically the 
Euclidean distance. Here, it is perhaps unsuprising that the K-means algorithm
has "better" performance than the GMM, as it explicity forms clusters based
on respectively minimizing and maximizing intra- and inter-cluster Euclidean 
distances.

```{r, cache=TRUE}
sil_km <- cluster::silhouette(clusters(coexp_km), dist(tcounts(coexp_km)))
summary(sil_km)
sil_df_km <- data.frame(as(sil_km, "matrix"))
sil_df_km$Cluster <- factor(sil_df_km$cluster)
sil_df_km <- sil_df_km[order(sil_df_km$cluster, sil_df_km$sil_width),]
ggplot(sil_df_km) +
  geom_col(aes(x=1:nrow(sil_df_km), y=sil_width, fill = Cluster)) + 
  ylab("Silhouette width") + 
  theme_bw() +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank())
```


## Dunn index

We next consider the Dunn index, which corresponds to the ratio of the smallest 
distance between clusters and the largest intra-cluster distance (diameter).
It is defined as follows:

\[ \textsf{DI} = \frac{\min\limits_{C_I, C_J, I\ne J} \left( \min\limits_{i\in C_I, j \in C_J} d(i,j)\right)}{\max\limits_{C_M} \textsf{diam}(C_M)} \]
where $\textsf{diam}(C_M)$ is the maximum distance among $i \in C_M$, $0 < \textsf{DI}$.

**Higher values of DI represent better results**. Once again, the Euclidean 
distance is used below.

What do you notice?

```{r, cache=TRUE}
coexp_gmm_dunn <- cluster.stats(d = dist(tcounts(coexp_gmm)), 
                             clusters(coexp_gmm))$dunn
coexp_km_dunn <- cluster.stats(d = dist(tcounts(coexp_km)), 
                                clusters(coexp_km))$dunn
cat("DI (GMM) =", coexp_gmm_dunn, "\nDI (K-means) =", coexp_km_dunn, "\n")
```


# Stability validation

Another way to validate a clustering result is to examine its stability with
respect to perturbations in the data -- the idea is that greater stability
reflects a higher-confidence result. The `r CRANpkg("clValid")` and 
`r CRANpkg("fpc")` packages offer several metrics for stability validation,
respectively based on bootstrap resampling and removing each column of the data
one-by-one.

As in the previous section, we make
use of the transformed normalized counts produced internally for clustering
by `r Biocpkg("coseq")` via `tcounts(coexp_gmm)` rather than the raw counts. Both 
methods considered here rerun the clustering algorithm for subsets of the data;
to this end, we make use of interface functions provied directly
by each package: respectively, `clMethods = c("model", kmeans")` and
`clustermethod = c(noisemclustCB, kmeansCBI)`.

## `r CRANpkg("clValid")`: removing each column one by one

To evaluate the stability of a clustering result, `r CRANpkg("clValid")`
proposes the successive removal of each column in the input data. For each
data subset, the clustering analysis is rerun, and several metrics are calculated
(with averages taken over all deleted columns):

- **Average proportion of non-overlap** (APN): measures the average proportion of 
observations not placed in the same cluster under both cases
- **Average distance** (AD): measures the average distance between 
observations placed in the same cluster under both cases
- **Average distance between means** (ADM): measures 
the average distance between cluster centers for observations placed in the same 
cluster under both cases
- **Figure of merit** (FOM): measures the average intra-cluster variance 
of the deleted column, where the clustering is based on the remaining 
(undeleted) columns.

Note that the APN, AD, and ADM are all based on the cross-classification table of the 
original clustering with the clustering based on the removal of one column.
**For all criteria, smaller values are better.**

We first examine results for the GMM.

```{r, cache=TRUE}
coexp_gmm_stability <- 
  clValid(as.matrix(tcounts(coexp_gmm)), 
          nClust=max(clusters(coexp_gmm)), maxitems = nrow(coexp_gmm),
          clMethods = "model",
          validation = "stability")
summary(coexp_gmm_stability)
```

We now examine results for the K-means algorithm.

```{r, cache=TRUE}
coexp_km_stability <- 
  clValid(as.matrix(tcounts(coexp_km)), 
          nClust=max(clusters(coexp_km)), maxitems = nrow(coexp_km),
          clMethods = "kmeans",
          validation = "stability")
summary(coexp_km_stability)
```

What do you notice?

## `r CRANpkg("fpc")`: bootstrap resampling of data 

To evaluate the stability of a clustering result, `r CRANpkg("fpc")` proposes
the use of bootstrap resampling of the data.  For each of the $B$
resampled data subsets, the clustering analysis is rerun and the Jaccard 
similarity index is calculated with respect to the original clusters. The
average clusterwise Jaccard bootstrap value can provide an indication 
of the stability of specific clusters.

Generally, a valid, stable cluster should yield a mean Jaccard similarity 
value of 0.75 or more, while values between 0.6 and 0.75 may be considered
as indicative of patterns in the data. Values < 0.6 indicate clusters with low
confidence. Jaccard similarity indices < 0.5 are considered to represent a "dissolved"
cluster; "recovered" clusters represent those with high Jaccard similarity
indices (although the specific threshold used in the package is not 
indicated in the documentation).

In general, **good performance is indicated by high average clusterwise 
Jaccard bootstrap values, few dissolved clusters, and a number of recovered
clusters as close to the number of bootstrap resamples $B$ as possible**.

We first examine the GMM results. Notice that we use a small number of 
bootstrap resamples here ($B$=20) to limit the computational time needed for
this tutorial -- **in practice, a larger number (e.g., $B$=100) should be used.**   

```{r, cache=TRUE}
coexp_gmm_boot <- 
  clusterboot(tcounts(coexp_gmm), B=20, k=max(clusters(coexp_gmm)), 
              seed=20,bootmethod="boot",
              clustermethod=noisemclustCBI)
print(coexp_gmm_boot)
```

We now examine the K-means results.

```{r, cache=TRUE}
coexp_km_boot <- 
  clusterboot(tcounts(coexp_km), B=20, k=max(clusters(coexp_km)), 
              seed=20,bootmethod="boot",
              clustermethod=kmeansCBI)
print(coexp_km_boot)
```

What do you notice?

# External validation

External validation metrics seek to evaluate the ability of a clustering 
algorithm to produce biologically meaningful clusters. For co-expression
analyses, this meaningfulness is typically evaluated with respect to:

- Gene ontology (GO) term annotations
- A priori functional categorizations of genes
- Pathway membership
- Lists of genes of interest
- ... or other relevant biological information

For this section, we thus generally assume that we have a set of $F$ known 
and potentially overlapping biological classes.

## Adjusted Rand Index

The adjusted Rand index (ARI) is used to compare two clustering partitions, or 
to compare a clustering result to known labels. The ARI corresponds to a 
corrected-for-chance version of the Rand index, and values close to 1 
indicate high agreement between the two sets of labels. The ARI can be used
here to compare the clusterings obtained between the GMM and K-means:

```{r, cache=TRUE}
adjustedRandIndex(clusters(coexp_gmm), clusters(coexp_km))

```

As an illustration, we can also calculate the ARI between chromosomes and
clustering labels. Here, the biological interest is perhaps limited, but
confirms that there is no association between GMM or K-means clusters
and chromosomes.

```{r, cache=TRUE}
chr_info <- rowData(dds)[match(rownames(coexp_gmm), 
                               rownames(rowData(dds))),"TXCHROM"]
table(chr_info)
adjustedRandIndex(clusters(coexp_gmm), chr_info)
adjustedRandIndex(clusters(coexp_km), chr_info)
```

## BHI and BSI

The `r CRANpkg("clValid")` package proposes two external validation measures:

- **Biological homogeneity index** (BHI): measures the average proportion of 
gene pairs that are clustered together which have matching biological functional classes
- **Biological stability index** (BSI):  inspects the consistency of clustering for genes with similar biological functionality (similar to other stability measures, where each 
sample is removed one at a time)

For each of these measures, we can use the Mouse annotation package
`r Biocpkg("org.Mm.eg.db")` from
[Bioconductor](https://www.bioconductor.org/) to specify the Gene Ontology (GO)
terms corresponding to the functional classes of genes. We focus in particular
on the Biological Process (BP) ontology for this analysis.

For each of these criteria, **values closer to 1 indicate better performance**.

```{r, cache=TRUE}
coexp_gmm_bio <- clValid(as.matrix(tcounts(coexp_gmm)), 
                        nClust = max(clusters(coexp_gmm)),
                        maxitems = nrow(coexp_gmm),
                        clMethods = c("model"),
                        validation = c("biological"),
                        annotation = "org.Mm.eg.db", 
                        GOcategory = "BP")
```

```{r, cache=TRUE}
coexp_km_bio <- clValid(as.matrix(tcounts(coexp_km)), 
                       nClust = max(clusters(coexp_km)),
                       maxitems = nrow(coexp_km),
                       clMethods = c("kmeans"),
                       validation = c("biological"),
                       annotation = "org.Mm.eg.db", 
                       GOcategory = "BP")
```

```{r, cache=TRUE}
optimalScores(coexp_gmm_bio)
optimalScores(coexp_km_bio)

```

What do you observe?

## GO enrichment analysis

The final assessment criterion we will examine concerns the *characterization*,
rather than the *validation*, of clusters. Specifically, we seek to identify
which biological processes (e.g., GO terms) appear to be enriched in
clusters of interest. This is done using an enrichment analysis, where we
seek to identify whether the proportion of genes annotated for a given 
GO term in our cluster of interest is significantly different than the 
proportion of annotated genes overall (i.e., the so-called *gene universe*). 
In this example, we take as a gene universe the genes considered for the
clustering analysis; it is debatable whether it should instead be defined
as the set of expressed genes that were included in the initial differential
analysis.

Although more sophisticated tests do exist,
most enrichment analyses are based on a Fisher's exact test. We make use of 
the `r Biocpkg("clusterProfiler")` package, which interfaces nicely with
visualization functions and Bioconductor annotation packages. As an example,
we focus on cluster 10 from the GMM clustering result.

```{r, cache=TRUE}
cl <- coexp_gmm
kchoose <- 10
ego <- enrichGO(gene = rownames(cl)[which(clusters(cl) == kchoose)],
                universe = rownames(cl),
                OrgDb = org.Mm.eg.db,
                ont = "BP")
```

```{r}
dotplot(ego, showCategory=15)
```


```{r, warning=FALSE}
head(summary(ego))
```


# Going further ...

There are many ways of performing clustering analysis and validating the
resulting clusters. For many of the measures of cluster validity presented in
this tutorial, values are to be interpreted relatively to compare between
results (algoriths, numbers of clusters, etc), and an objective threshold
establishing a "good" versus a "bad" clustering result (or individual cluster) 
may not exist. 

To go further, you could try the following:

- Generate random data (or several random datasets), and evaluate the various validation criterion 
presented in this tutorial. How do the values compare to those of the observed
data? 
- Consider one of the many other clustering algorithms available, and compare to
the results shown for K-means and GMM: 
hierarchical clustering , self-organizing maps (SOM), DIvisive ANAlysis (DIANA),
partitioning around mediods (PAM), just to name a few...
- Identify consensus clusters when varying the number of clusters or across
different clustering algorithms, for example with `r Biocpkg("ConsensusClusterPlus")`.

# Appendix: Creating initial data files

The differential and co-expression analysis results that were loaded in the 
first step of this tutorial were generated with the following code:

```{r, eval=FALSE}
library(RnaSeqGeneEdgeRQL)
library(DESeq2)
library(Mus.musculus) 

 
## Read in targets file --------------------------------------------------------
targetsFile <- 
  system.file("extdata", "targets.txt", package="RnaSeqGeneEdgeRQL")
targets <- read.delim(targetsFile, stringsAsFactors=FALSE)
targets$ID <- rownames(targets)
targets$Status <- factor(targets$Status, 
                         levels = c("virgin", "pregnant", "lactating"))
targets


## Download gene-wise read counts from NCBI ------------------------------------
FileURL <- paste(
     "http://www.ncbi.nlm.nih.gov/geo/download/?acc=GSE60450",
     "format=file",
     "file=GSE60450_Lactation-GenewiseCounts.txt.gz",
     sep="&")
download.file(FileURL, "GSE60450_Lactation-GenewiseCounts.txt.gz")

GenewiseCounts <- 
  read.delim("GSE60450_Lactation-GenewiseCounts.txt.gz",
             row.names="EntrezGeneID")
colnames(GenewiseCounts) <- substring(colnames(GenewiseCounts),1,7)
counts <- GenewiseCounts[,-1] ## First column is gene lengths
counts <- counts[-which(rowSums(counts) == 0),]

dim(counts)
head(counts)


## Gene names ------------------------------------------------------------------
geneid <- rownames(counts) 
genes <- select(Mus.musculus, keys=geneid, columns=c("SYMBOL", "TXCHROM"), 
                keytype="ENTREZID")
## Remove multi-mapped genes
genes <- genes[!duplicated(genes$ENTREZID),]
all.equal(unlist(genes$ENTREZID), rownames(counts))
dim(genes)
head(genes)


## Differential analysis to screen DE genes ------------------------------------
dds <- DESeqDataSetFromMatrix(counts, targets, design = ~ Status)
rowData(dds) <- genes
## Remove weakly expressed genes
keep <- rowSums(counts(dds) >= 20) >= 2
dds <- dds[keep,]
## Remove genes missing a symbol or chromosome
keep2 <- which(rowSums(is.na(rowData(dds))) == 0)
dds <- dds[keep2,]
dds <- DESeq(dds, test="LRT", reduced = ~1)
res <- results(dds, alpha = 0.05)
hist(res$pvalue, breaks = 50, main = "Raw p-values")


## Run coseq for co-expression analysis ----------------------------------------
coexp_gmm_all <- vector("list", length = 20)
for(i in 1:20) {
    coexp_gmm_all[[i]] <- coseq(dds, alpha = 0.05, K = 2:20, 
                                model = "Normal", transformation = "arcsin")
}
ICL_all <- unlist(lapply(coexp_gmm_all, function(x) min(ICL(x))))
best_gmm_result <- which.min(ICL_all)
coexp_gmm <- coexp_gmm_all[[best_gmm_result]]

coexp_km <- coseq(dds, alpha = 0.05, K = 2:20, seed=12345,
                  model = "kmeans", transformation = "arcsin")

## Save DE and coseq results ---------------------------------------------------
saveRDS(dds, file = "Fu-GSE60450_dds.rds")
saveRDS(coexp_gmm, file = "coexp_gmm.rds")
saveRDS(coexp_km, file = "coexp_km.rds")
```

These steps were hugely inspired by the workflows found in the 
[RnaSeqGeneEdgeRQL vignette]( https://bioconductor.org/packages/release/workflows/vignettes/RnaSeqGeneEdgeRQL/inst/doc/edgeRQL.html) and in a [F1000 Software Tool article](https://f1000research.com/articles/5-1408).



# Session info {.unnumbered}

```{r sessionInfo, echo=FALSE}
sessionInfo()
```
